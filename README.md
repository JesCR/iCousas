# üõ∞Ô∏è iCousas - Recopilador de Datos de Sensores Meteorol√≥gicos

Un script robusto y de producci√≥n en Python para recopilar, procesar y almacenar datos meteorol√≥gicos de sensores iCousas utilizando autenticaci√≥n Keycloak y base de datos SQL Server.

## üìã Tabla de Contenidos

- [Caracter√≠sticas](#caracter√≠sticas)
- [Arquitectura](#arquitectura)
- [Requisitos Previos](#requisitos-previos)
- [Instalaci√≥n](#instalaci√≥n)
- [Configuraci√≥n](#configuraci√≥n)
- [Uso](#uso)
- [Estructura del Proyecto](#estructura-del-proyecto)
- [Logging y Monitoreo](#logging-y-monitoreo)
- [Soluci√≥n de Problemas](#soluci√≥n-de-problemas)
- [Desarrollo](#desarrollo)
- [Licencia](#licencia)

## ‚ú® Caracter√≠sticas

### üîê Autenticaci√≥n Segura
- **Autenticaci√≥n Keycloak**: Resource Owner Password Flow
- **Gesti√≥n autom√°tica de tokens**: Refresh autom√°tico cuando expira
- **Reintentos con backoff exponencial**: Manejo robusto de fallos temporales
- **Seguridad**: Credenciales nunca expuestas en logs

### üìä Procesamiento de Datos
- **API RESTful**: Consulta datos hist√≥ricos de sensores
- **Ventana temporal configurable**: √öltimos N minutos de datos
- **Paginaci√≥n autom√°tica**: Manejo de grandes vol√∫menes de datos
- **Normalizaci√≥n**: Conversi√≥n autom√°tica de tipos de datos
- **Conversi√≥n de unidades**: atmosphericPressure kPa ‚Üí hPa (canal 4)
- **Validaci√≥n**: Verificaci√≥n de integridad de datos
- **Redondeo robusto de minutos**: Algoritmo avanzado que evita hour=24 y minute=60
- **Ordenamiento inteligente**: Registros ordenados por fecha para procesamiento correcto
- **Filtrado inteligente**: Evita reprocesar datos ya procesados bas√°ndose en metadatos
- **Barra de progreso visual**: Seguimiento en tiempo real del procesamiento
- **Procesamiento en dos fases**: API ‚Üí TemporalDatosBrutos_iCousas ‚Üí TemporalDatosBrutos

### üóÑÔ∏è Almacenamiento en Base de Datos
- **SQL Server**: Compatibilidad completa
- **Operaci√≥n MERGE**: Insert/Update autom√°tico (Upsert)
- **Transacciones ACID**: Garant√≠a de integridad de datos
- **Tablas temporales**: Optimizaci√≥n de rendimiento
- **Manejo inteligente de duplicados**: Verificaci√≥n previa con redondeo de floats
- **Actualizaci√≥n autom√°tica de metadatos**: Tabla CruceEstacionesListaEstacionesFechasUltimosDatos (estaciones pre-registradas)
- **Manejo de errores**: Rollback autom√°tico en fallos

### üìù Logging Avanzado
- **Archivo + Consola**: Logging dual simult√°neo
- **Rotaci√≥n autom√°tica**: Archivo por hora (formato YYYY-MM-DD-HH.txt)
- **Niveles configurables**: DEBUG, INFO, WARNING, ERROR
- **Informaci√≥n detallada**: Curl equivalents, headers, respuestas
- **Consultas SQL visibles**: Para debugging de base de datos
- **Barra de progreso integrada**: Seguimiento visual en logs
- **Seguridad**: Contrase√±as ocultas en logs

### üõ†Ô∏è Caracter√≠sticas T√©cnicas
- **Python 3.11+**: √öltima versi√≥n LTS
- **Tipado est√°tico**: Type hints completos
- **Manejo de excepciones**: Tratamiento robusto de errores
- **Configuraci√≥n externa**: Variables de entorno
- **Documentaci√≥n completa**: Docstrings en espa√±ol

## üèóÔ∏è Arquitectura

```
iCousas Data Collector
‚îú‚îÄ‚îÄ üîê AuthManager (Keycloak)
‚îú‚îÄ‚îÄ üì° SensorDataFetcher (API REST)
‚îú‚îÄ‚îÄ üîÑ DataProcessor (ETL)
‚îú‚îÄ‚îÄ üíæ DatabaseManager (SQL Server)
‚îú‚îÄ‚îÄ üîÑ DataIngestionManager (Procesamiento Final)
‚îú‚îÄ‚îÄ üìä ProgressMonitor (Barras de Progreso)
‚îî‚îÄ‚îÄ üìù Logger (Archivo + Consola)
```

### Componentes Principales

1. **AuthManager**: Gestiona autenticaci√≥n OAuth2 con Keycloak
2. **SensorDataFetcher**: Consulta API de sensores con paginaci√≥n
3. **DataProcessor**: Normaliza y valida datos meteorol√≥gicos
4. **DatabaseManager**: Ejecuta operaciones MERGE en SQL Server
5. **DataIngestionManager**: Procesa datos finales de TemporalDatosBrutos_iCousas ‚Üí TemporalDatosBrutos
6. **ProgressMonitor**: Muestra barras de progreso visual en tiempo real
7. **Sistema de Logging**: Registra todas las operaciones detalladamente

## üìã Requisitos Previos

### üîß Requisitos del Sistema
- **SO**: Windows 10/11, Linux, macOS
- **Python**: 3.11 o superior
- **RAM**: M√≠nimo 512MB (recomendado 1GB)
- **Espacio en disco**: 100MB para logs y datos temporales

### üóÑÔ∏è Base de Datos
- **SQL Server**: 2016 o superior
- **Controlador ODBC**: SQL Server Native Client 11.0+
- **Tablas requeridas**:
  - `TemporalDatosBrutos_iCousas` (temporal - fase 1)
  - `TemporalDatosBrutos` (final - fase 2)
  - `AuxEstacionesCodigos` (mapeo estaciones)
  - `VIDX_AMC_ConNulls` (configuraci√≥n canales)
  - `CruceEstacionesListaEstacionesFechasUltimosDatos` (metadatos)

#### üìù Esquemas de Tablas

**Tabla Temporal (Fase 1):**
```sql
CREATE TABLE dbo.TemporalDatosBrutos_iCousas (
    entityId                  NVARCHAR(200)   NOT NULL,
    [index]                   DATETIME2       NOT NULL,
    airTemperature            FLOAT           NULL,
    atmosphericPressure       FLOAT           NULL,
    batteryVoltage            FLOAT           NULL,
    lightningAverageDistance  FLOAT           NULL,
    lightningStrikeCount      FLOAT           NULL,
    maximumWindSpeed          FLOAT           NULL,
    precipitation             FLOAT           NULL,
    relativeHumidity          FLOAT           NULL,
    solarRadiation            FLOAT           NULL,
    vaporPressure             FLOAT           NULL,
    windDirection             FLOAT           NULL,
    windSpeed                 FLOAT           NULL,
    CONSTRAINT PK_TemporalDatosBrutos_iCousas PRIMARY KEY (entityId, [index])
);
```

**Tabla Final (Fase 2):**
```sql
CREATE TABLE dbo.TemporalDatosBrutos (
    lnEstacion                INT             NOT NULL,
    FechaHora                 SMALLDATETIME   NOT NULL,
    Canal                     SMALLINT        NOT NULL,
    Valor                     REAL            NOT NULL,
    FechaEntrada              SMALLDATETIME   NULL,
    CONSTRAINT PK_new_TemporalDatosBrutos PRIMARY KEY CLUSTERED (lnEstacion, FechaHora, Canal)
);
```

**Tabla de Metadatos:**
```sql
CREATE TABLE dbo.CruceEstacionesListaEstacionesFechasUltimosDatos (
    lnEstacion                      INT           NOT NULL,
    lnTipoFechaUltimoDato           INT           NOT NULL,
    Fecha                          SMALLDATETIME NOT NULL,
    CONSTRAINT PK_new_CruceListaEstacionesFechasUltimosDatos PRIMARY KEY CLUSTERED (lnEstacion, lnTipoFechaUltimoDato)
);
```

### üåê Conectividad
- **API iCousas**: `https://sensors.icousas.gal`
- **Keycloak**: `https://iam.icousas.gal`
- **SQL Server**: Acceso a servidor de base de datos

## üöÄ Instalaci√≥n

### Paso 1: Clonar/Descargar el Proyecto
```bash
# Crear directorio del proyecto
mkdir icousas-data-collector
cd icousas-data-collector

# Copiar archivos del proyecto
# main.py, requirements.txt, .env.example
```

### Paso 2: Instalar Python
Verificar instalaci√≥n de Python 3.11+:
```bash
python --version
# Debe mostrar Python 3.11.x o superior
```

### Paso 3: Instalar Dependencias
```bash
# Instalar dependencias Python
pip install -r requirements.txt
```

#### Dependencias Incluidas:
- `requests>=2.31.0` - Cliente HTTP
- `pyodbc>=5.2.0` - Conector SQL Server
- `python-dotenv>=1.1.1` - Gesti√≥n de variables de entorno
- `python-dateutil>=2.9.0` - Manejo de fechas

### Paso 4: Verificar Instalaci√≥n
```bash
python -c "import requests, pyodbc, dotenv, dateutil; print('‚úÖ Todas las dependencias instaladas correctamente')"
```

## ‚öôÔ∏è Configuraci√≥n

### Paso 1: Configurar Variables de Entorno
```bash
# Copiar archivo de ejemplo
copy .env.example .env

# Editar .env con tus valores reales
notepad .env
```

### Paso 2: Archivo de Configuraci√≥n (.env)

```bash
# ===========================================
# CONFIGURACI√ìN DE AUTENTICACI√ìN KEYCLOAK
# ===========================================
KEYCLOAK_URL=https://iam.icousas.gal/auth/realms/icousas/protocol/openid-connect/token
KEYCLOAK_CLIENT_ID=icousas-backend
KEYCLOAK_USERNAME=tu_usuario
KEYCLOAK_PASSWORD=tu_contrase√±a
KEYCLOAK_GRANT_TYPE=password

# ===========================================
# CONFIGURACI√ìN HTTP
# ===========================================
HTTP_TIMEOUT=15
HTTP_MAX_RETRIES=3
HTTP_RETRY_BACKOFF_BASE=1
HTTP_VERIFY_SSL=false

# ===========================================
# CONFIGURACI√ìN API SENSORES
# ===========================================
SENSORS_BASE_URL=https://sensors.icousas.gal/v1/data/historic/devices
SENSORS_ATTRIBUTES=airTemperature,atmosphericPressure,batteryVoltage,lightningAverageDistance,lightningStrikeCount,maximumWindSpeed,precipitation,relativeHumidity,solarRadiation,vaporPressure,windDirection,windSpeed
SENSORS_TIME_WINDOW_MINUTES=20
SENSORS_LAST_N=100
SENSORS_LIMIT=100
SENSORS_ORGANIZATION=MedioAmbiente

# ===========================================
# CONFIGURACI√ìN BASE DE DATOS SQL SERVER
# ===========================================
DB_SERVER=tu_servidor_sql_server
DB_USERNAME=tu_usuario_db
DB_PASSWORD=tu_contrase√±a_db
DB_NAME=tu_base_datos
DB_CONNECTION_TIMEOUT=30

# ===========================================
# CONFIGURACI√ìN DE LOGGING
# ===========================================
LOG_LEVEL=INFO
```

### Paso 3: Verificar Configuraci√≥n
```bash
python main.py
# Debe mostrar "Variables de entorno cargadas exitosamente"
```

## üéØ Uso

### Flujo de Procesamiento

El script ejecuta un **procesamiento en dos fases**:

1. **Fase 1**: API ‚Üí `TemporalDatosBrutos_iCousas`
   - Obtiene datos de la API iCousas
   - Los almacena en tabla temporal
   - Barra de progreso visual

2. **Fase 2**: `TemporalDatosBrutos_iCousas` ‚Üí `TemporalDatosBrutos`
   - Procesa datos de tabla temporal
   - Los mapea a formato final usando configuraci√≥n de canales
   - Actualiza metadatos de fechas
   - Elimina registros procesados
   - Barra de progreso visual

### Ejecuci√≥n B√°sica
```bash
python main.py
```

### Ejecuci√≥n con Logging Detallado
```bash
# Editar .env y cambiar:
LOG_LEVEL=DEBUG

# Ejecutar
python main.py
```

### Ejecuci√≥n con Consultas SQL Visibles
```bash
# Editar .env y cambiar:
LOG_LEVEL=DEBUG

# Ejecutar - mostrar√° todas las consultas SQL ejecutadas
python main.py
```

### Ejecuci√≥n Programada (Windows Task Scheduler)
```batch
# Crear tarea programada para ejecutar cada hora
schtasks /create /tn "iCousasDataCollector" /tr "python D:\test\iCousas\main.py" /sc hourly /mo 1
```

### Ejecuci√≥n Programada (Linux Cron)
```bash
# Editar crontab
crontab -e

# Agregar l√≠nea para ejecutar cada hora
0 * * * * /usr/bin/python3 /ruta/a/main.py
```

## üìÅ Estructura del Proyecto

```
icousas-data-collector/
‚îú‚îÄ‚îÄ üìÑ main.py                 # Script principal
‚îú‚îÄ‚îÄ üìÑ requirements.txt        # Dependencias Python
‚îú‚îÄ‚îÄ üìÑ .env.example           # Plantilla de configuraci√≥n
‚îú‚îÄ‚îÄ üìÑ .env                   # Configuraci√≥n personal (no versionar)
‚îú‚îÄ‚îÄ üìÅ logs/                  # Directorio de logs
‚îÇ   ‚îú‚îÄ‚îÄ 2025-09-09-12.txt    # Log principal de las 12:00
‚îÇ   ‚îú‚îÄ‚îÄ 2025-09-09-12_ingest.txt  # Log de ingesti√≥n de las 12:00
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ üìÑ README.md             # Esta documentaci√≥n
‚îî‚îÄ‚îÄ üìÅ __pycache__/          # Archivos compilados Python
```

### Componentes del Script
- **AuthManager**: Autenticaci√≥n Keycloak
- **SensorDataFetcher**: Consulta API de sensores
- **DataProcessor**: Procesamiento inicial con barra de progreso
- **DatabaseManager**: Operaciones SQL Server
- **DataIngestionManager**: Procesamiento final con barra de progreso
- **Sistema de Logging**: Logs separados para cada fase

## üìä Logging y Monitoreo

### Sistema de Logs
- **Ubicaci√≥n**: `logs/YYYY-MM-DD-HH.txt`
- **Rotaci√≥n**: Autom√°tica por hora
- **Contenido**: Informaci√≥n detallada de todas las operaciones

### Ejemplo de Log Exitoso

**Log Principal (main.py):**
```
2025-09-09 12:00:01 - __main__ - INFO - Empezamos
2025-09-09 12:00:01 - __main__ - INFO - Variables de entorno cargadas exitosamente (20 variables)
2025-09-09 12:00:01 - __main__ - INFO - Configuraci√≥n de entorno validada
2025-09-09 12:00:01 - __main__ - INFO - Autenticando con Keycloak...
2025-09-09 12:00:02 - __main__ - INFO - Autenticaci√≥n exitosa
2025-09-09 12:00:02 - __main__ - INFO - Iniciando obtenci√≥n de datos...
2025-09-09 12:00:03 - __main__ - INFO - Se obtuvieron exitosamente 150 dispositivos totales
Procesando dispositivos: [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100% (150/150)
2025-09-09 12:00:04 - __main__ - INFO - Se normalizaron exitosamente 150 registros
2025-09-09 12:00:04 - __main__ - INFO - Almacenando datos en base de datos...
2025-09-09 12:00:05 - __main__ - INFO - Iniciando proceso de ingesti√≥n de datos...
Procesando registros: [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100% (150/150)
2025-09-09 12:00:06 - __main__ - INFO - Progreso: 150/150 registros procesados (100%)
2025-09-09 12:00:06 - __main__ - INFO - Proceso de ingesti√≥n completado: 150 registros procesados, 150 registros eliminados
2025-09-09 12:00:06 - __main__ - INFO - Trabajo completado exitosamente en 5.42 segundos. Procesados 150 registros: 150 insertados/actualizados, 150 ingestados, 150 eliminados
```

**Log de Ingesti√≥n (ingest):**
```
2025-09-09 12:00:05 - ingestion - INFO - Iniciando proceso de ingesti√≥n de datos...
2025-09-09 12:00:05 - ingestion - INFO - Leyendo registros de TemporalDatosBrutos_iCousas...
2025-09-09 12:00:05 - ingestion - INFO - Se leyeron 150 registros de TemporalDatosBrutos_iCousas
2025-09-09 12:00:05 - ingestion - INFO - Iniciando procesamiento de 150 registros...
2025-09-09 12:00:06 - ingestion - INFO - Progreso: 150/150 registros procesados (100%)
2025-09-09 12:00:06 - ingestion - INFO - Proceso de ingesti√≥n completado: 150 registros procesados, 150 registros eliminados
```

### Monitoreo de Logs
```bash
# Ver logs m√°s recientes
Get-ChildItem logs\*.txt | Sort-Object LastWriteTime -Descending | Select-Object -First 5

# Buscar errores en logs
Select-String -Path logs\*.txt -Pattern "ERROR" -CaseSensitive:$false

# Contar l√≠neas de log por hora
Get-ChildItem logs\*.txt | ForEach-Object { "$($_.Name): $((Get-Content $_.FullName).Count) l√≠neas" }
```

## üîß Soluci√≥n de Problemas

### Problema: Error de Autenticaci√≥n (401)
```
‚ùå Authentication failed: 401 - {"error":"invalid_grant","error_description":"Invalid user credentials"}
```

**Soluciones:**
1. Verificar credenciales en `.env`
2. Asegurar que la contrase√±a termine con `#`
3. Confirmar que el usuario tenga permisos en Keycloak

### Problema: Error de Conexi√≥n SSL
```
‚ùå HTTPSConnectionPool: Max retries exceeded (Caused by SSLCertVerificationError)
```

**Soluciones:**
1. Configurar `HTTP_VERIFY_SSL=false` en `.env`
2. Verificar conectividad a la red corporativa
3. Revisar configuraci√≥n de proxy si aplica

### Problema: Variables de Entorno Faltantes
```
‚ùå Missing required environment variables: KEYCLOAK_URL, KEYCLOAK_PASSWORD
```

**Soluciones:**
1. Verificar que `.env` exista y est√© completo
2. Revisar sintaxis (especialmente contrase√±as con `#`)
3. Asegurar que no haya BOM UTF-8/UTF-16

### Problema: Error de Base de Datos
```
‚ùå Database operation failed: Login timeout expired
```

**Soluciones:**
1. Verificar credenciales de SQL Server
2. Confirmar conectividad al servidor
3. Revisar configuraci√≥n de firewall
4. Verificar que la tabla exista

### Problema: Memoria Insuficiente
```
‚ùå MemoryError: Unable to allocate array
```

**Soluciones:**
1. Reducir `SENSORS_LIMIT` en configuraci√≥n
2. Procesar datos en lotes m√°s peque√±os
3. Aumentar RAM del sistema

### Debugging Avanzado
```bash
# Ejecutar con logging m√°ximo
# Editar .env: LOG_LEVEL=DEBUG
python main.py

# Ver logs detallados
Get-Content logs\*.txt -Tail 50
```

## üõ†Ô∏è Desarrollo

### Configuraci√≥n del Entorno de Desarrollo
```bash
# Instalar dependencias de desarrollo
pip install black flake8 mypy pytest

# Ejecutar linter
flake8 main.py

# Formatear c√≥digo
black main.py

# Verificar tipos
mypy main.py
```

### Estructura del C√≥digo
```python
class AuthManager:
    """Maneja la autenticaci√≥n Keycloak."""
    # M√©todos: get_access_token, _authenticate, _create_session

class SensorDataFetcher:
    """Maneja la obtenci√≥n de datos desde la API."""
    # M√©todos: fetch_data, _calculate_time_window

class DataProcessor:
    """Procesa y normaliza datos de sensores."""
    # M√©todos: process_devices, normalize_record, parse_datetime

class DatabaseManager:
    """Maneja operaciones de base de datos SQL Server."""
    # M√©todos: upsert_records, _get_connection

def main():
    """Funci√≥n principal del programa."""
    # L√≥gica principal de ejecuci√≥n
```

### Testing
```python
# Ejecutar tests (si se implementan)
pytest tests/

# Ejecutar con coverage
pytest --cov=main --cov-report=html
```

## üìà M√©tricas y Rendimiento

### Rendimiento T√≠pico
- **Tiempo de ejecuci√≥n**: 3-15 segundos
- **Registros procesados**: 100-1000 por ejecuci√≥n
- **Memoria utilizada**: 50-200MB
- **CPU**: 5-15% durante ejecuci√≥n

### Optimizaciones
- **Tablas temporales**: Reduce I/O en base de datos
- **Bulk inserts**: Optimizaci√≥n de inserciones masivas
- **Paginaci√≥n**: Manejo eficiente de grandes datasets
- **Pooling de conexiones**: Reutilizaci√≥n de conexiones HTTP

## ü§ù Contribuci√≥n

1. **Fork** el proyecto
2. Crear rama para feature: `git checkout -b feature/nueva-funcionalidad`
3. **Commit** cambios: `git commit -am 'Agrega nueva funcionalidad'`
4. **Push** a rama: `git push origin feature/nueva-funcionalidad`
5. Crear **Pull Request**

### Est√°ndares de C√≥digo
- **PEP 8**: Estilo de c√≥digo Python
- **Type hints**: Anotaciones de tipo completas
- **Docstrings**: Documentaci√≥n en espa√±ol
- **Logging**: Mensajes informativos en espa√±ol
- **Comentarios**: Explicativos y √∫tiles

## üìÑ Licencia

Este proyecto est√° bajo la Licencia MIT. Ver archivo `LICENSE` para m√°s detalles.

## üìû Soporte

Para soporte t√©cnico o reportar problemas:

1. **Revisar logs**: `logs/YYYY-MM-DD-HH.txt`
2. **Verificar configuraci√≥n**: Archivo `.env`
3. **Documentar el error**: Incluir logs completos
4. **Crear issue**: Con descripci√≥n detallada del problema

## üèÜ Caracter√≠sticas Destacadas

- ‚úÖ **Redondeo Inteligente de Minutos**: Fechas normalizadas para sistema de almacenamiento
- ‚úÖ **Procesamiento en Dos Fases**: API ‚Üí Temporal ‚Üí Final con barras de progreso
- ‚úÖ **Manejo Inteligente de Duplicados**: Verificaci√≥n con redondeo de floats
- ‚úÖ **Actualizaci√≥n Autom√°tica de Metadatos**: Tabla de fechas de √∫ltimo dato
- ‚úÖ **Consultas SQL Visibles**: Para debugging completo de base de datos
- ‚úÖ **Logging Dual**: Logs separados para cada fase del procesamiento
- ‚úÖ **Barra de Progreso Visual**: Seguimiento en tiempo real sin dependencias externas
- ‚úÖ **Producci√≥n Ready**: C√≥digo robusto y probado
- ‚úÖ **Documentaci√≥n Completa**: En espa√±ol con ejemplos actualizados
- ‚úÖ **Manejo de Errores**: Tratamiento completo de excepciones
- ‚úÖ **Configuraci√≥n Flexible**: Variables de entorno
- ‚úÖ **Seguridad**: Credenciales protegidas
- ‚úÖ **Rendimiento**: Optimizado para grandes vol√∫menes
- ‚úÖ **Mantenibilidad**: C√≥digo modular y bien estructurado

---

**Desarrollado con ‚ù§Ô∏è para el proyecto iCousas**

*√öltima actualizaci√≥n: Septiembre 2025*

---

## üìã Historial de Cambios (v2.0.0)

### ‚ú® Nuevas Funcionalidades
- **DataIngestionManager**: Procesamiento independiente de datos finales
- **Redondeo inteligente de minutos**: Fechas normalizadas a minutos permitidos (0,10,20,30,40,50)
- **Ordenamiento inteligente**: Registros ordenados por fecha para procesamiento correcto
- **Filtrado inteligente**: Evita reprocesar datos ya procesados
- **Barras de progreso visual**: Seguimiento en tiempo real sin dependencias externas
- **Actualizaci√≥n autom√°tica de metadatos**: Gesti√≥n de fechas de √∫ltimo dato (estaciones pre-registradas)
- **Consultas SQL visibles**: Debugging completo de operaciones de BD

### üîß Mejoras T√©cnicas
- **Manejo robusto de duplicados**: Verificaci√≥n previa con redondeo de floats
- **Conversi√≥n de unidades meteorol√≥gicas**: atmosphericPressure √ó10 (kPa‚ÜíhPa)
- **Correcci√≥n de conversi√≥n SMALLDATETIME**: Formatos de fecha compatibles
- **Parsing avanzado de fechas ISO 8601**: datetime.fromisoformat + fallback dateutil + redondeo robusto
- **Validaci√≥n de integridad**: Estaciones deben estar pre-registradas en metadatos
- **Logging dual**: Logs separados para cada fase de procesamiento
- **Transacciones at√≥micas**: Mejor integridad de datos
- **Manejo de errores mejorado**: Mensajes detallados y recuperaci√≥n autom√°tica
